{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with SciKit-Learn and skorch\n",
    "\n",
    "This notebooks shows how to define and train a simple Neural-Network with PyTorch and use it via skorch with SciKit-Learn.\n",
    "\n",
    "<table align=\"left\"><td>\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
    "</td><td>\n",
    "<a target=\"_blank\" href=\"https://github.com/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "Using SciKit-Learns ```fetch_openml``` to load MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "\n",
    "Each image of the MNIST dataset is encoded in a 784 dimensional vector, representing a 28 x 28 pixel image. Each pixel has a value between 0 and 255, corresponding to the grey-value of a pixel.<br />\n",
    "The above ```featch_mldata``` method to load MNIST returns ```data``` and ```target``` as ```uint8``` which we convert to ```float32``` and ```int64``` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data.astype('float32')\n",
    "y = mnist.target.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 255.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.min(), X.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: data is not normalized. We will use the sklearn standard scaler to do this in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(X_train.shape[0] + X_test.shape[0] == mnist.data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52500, 784), (52500,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print a selection of training images and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(X, y):\n",
    "    \"\"\"Plot the first 5 images and their labels in a row.\"\"\"\n",
    "    for i, (img, y) in enumerate(zip(X[:5].reshape(5, 28, 28), y[:5])):\n",
    "        plt.subplot(151 + i)\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_example(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Neural Network with PyTorch\n",
    "Simple, fully connected neural network with one hidden layer. Input layer has 784 dimensions (28x28), hidden layer has 98 (= 784 / 8) and output layer 10 neurons, representing digits 0 - 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jamesl\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dim = X.shape[1]\n",
    "hidden_dim = int(mnist_dim/8)\n",
    "output_dim = len(np.unique(mnist.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 98, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_dim, hidden_dim, output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Neural network in PyTorch's framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(self, num_hidden=100, dropout=.5, nonlin=F.relu):\n",
    "        super(ClassifierModule, self).__init__()\n",
    "        \n",
    "        self.hidden = nn.Linear(784, num_hidden)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output = nn.Linear(num_hidden, 10)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.hidden(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skorch allows to use PyTorch's networks in the SciKit-Learn setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=.1,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine network with standard scaler in pipeline\n",
    "To avoid big weights that deal with the pixel values from between [0, 255], we scale `X` down. A commonly used range is [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a standard scaler step before\n",
    "pipe = Pipeline([\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('net', net),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8389\u001b[0m       \u001b[32m0.8868\u001b[0m        \u001b[35m0.4033\u001b[0m  1.6604\n",
      "      2        \u001b[36m0.4273\u001b[0m       \u001b[32m0.9088\u001b[0m        \u001b[35m0.3095\u001b[0m  1.9302\n",
      "      3        \u001b[36m0.3575\u001b[0m       \u001b[32m0.9232\u001b[0m        \u001b[35m0.2617\u001b[0m  1.9237\n",
      "      4        \u001b[36m0.3182\u001b[0m       \u001b[32m0.9296\u001b[0m        \u001b[35m0.2399\u001b[0m  1.9467\n",
      "      5        \u001b[36m0.2908\u001b[0m       \u001b[32m0.9361\u001b[0m        \u001b[35m0.2159\u001b[0m  1.9336\n",
      "      6        \u001b[36m0.2720\u001b[0m       \u001b[32m0.9411\u001b[0m        \u001b[35m0.1976\u001b[0m  1.9015\n",
      "      7        \u001b[36m0.2552\u001b[0m       \u001b[32m0.9459\u001b[0m        \u001b[35m0.1857\u001b[0m  1.9372\n",
      "      8        \u001b[36m0.2429\u001b[0m       \u001b[32m0.9485\u001b[0m        \u001b[35m0.1748\u001b[0m  1.9228\n",
      "      9        \u001b[36m0.2294\u001b[0m       \u001b[32m0.9514\u001b[0m        \u001b[35m0.1651\u001b[0m  1.9010\n",
      "     10        \u001b[36m0.2195\u001b[0m       \u001b[32m0.9532\u001b[0m        \u001b[35m0.1614\u001b[0m  1.9091\n",
      "     11        \u001b[36m0.2146\u001b[0m       \u001b[32m0.9550\u001b[0m        \u001b[35m0.1530\u001b[0m  1.9010\n",
      "     12        \u001b[36m0.2059\u001b[0m       \u001b[32m0.9561\u001b[0m        \u001b[35m0.1469\u001b[0m  1.9163\n",
      "     13        \u001b[36m0.2002\u001b[0m       \u001b[32m0.9579\u001b[0m        \u001b[35m0.1414\u001b[0m  1.9218\n",
      "     14        \u001b[36m0.1940\u001b[0m       \u001b[32m0.9583\u001b[0m        \u001b[35m0.1385\u001b[0m  1.9823\n",
      "     15        \u001b[36m0.1901\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.1333\u001b[0m  1.9040\n",
      "     16        \u001b[36m0.1834\u001b[0m       \u001b[32m0.9607\u001b[0m        \u001b[35m0.1323\u001b[0m  2.1948\n",
      "     17        \u001b[36m0.1779\u001b[0m       0.9604        \u001b[35m0.1318\u001b[0m  1.9422\n",
      "     18        \u001b[36m0.1745\u001b[0m       0.9606        \u001b[35m0.1307\u001b[0m  1.9070\n",
      "     19        \u001b[36m0.1702\u001b[0m       \u001b[32m0.9625\u001b[0m        \u001b[35m0.1253\u001b[0m  2.0927\n",
      "     20        \u001b[36m0.1672\u001b[0m       \u001b[32m0.9636\u001b[0m        \u001b[35m0.1239\u001b[0m  1.9428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scale', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('net',\n",
       "                 <class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (hidden): Linear(in_features=784, out_features=100, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (output): Linear(in_features=100, out_features=10, bias=True)\n",
       "  ),\n",
       "))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629714285714286"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of about 96% for a network with only one hidden layer is not too bad.\n",
    "\n",
    "Let's take a look at some predictions that went wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_mask = y_pred != y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_example(X_test[error_mask], y_pred[error_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "params = {\n",
    "    'module__dropout': [.25, .5],\n",
    "    'module__num_hidden': [50, 100],\n",
    "}\n",
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy', verbose=0)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_, gs.best_params_)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network\n",
    "PyTorch expects a 4 dimensional tensor as input for its 2D convolution layer. The dimensions represent:\n",
    "* Batch size\n",
    "* Number of channel\n",
    "* Height\n",
    "* Width\n",
    "\n",
    "As initial batch size the number of examples needs to be provided. MNIST data has only one channel. As stated above, each MNIST vector represents a 28x28 pixel image. Hence, the resulting shape for PyTorch tensor needs to be (x, 1, 28, 28). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "XCnn = X.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 1, 28, 28)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XCnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "XCnn_train, XCnn_test, y_train, y_test = train_test_split(XCnn, y, test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52500, 1, 28, 28), (52500,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XCnn_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(Cnn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2_drop = nn.Dropout2d(p=dropout)\n",
    "        self.fc1 = nn.Linear(1600, 100)  # 1600 = number channels * width * height\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        self.fc1_drop = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = torch.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        \n",
    "        # flatten over channel, height and width = 1600\n",
    "        x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
    "        \n",
    "        x = torch.relu(self.fc1_drop(self.fc1(x)))\n",
    "        x = torch.softmax(self.fc2(x), dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "cnn = NeuralNetClassifier(\n",
    "    Cnn,\n",
    "    max_epochs=10,\n",
    "    lr=.002,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m3.9018\u001b[0m       \u001b[32m0.9656\u001b[0m        \u001b[35m0.1243\u001b[0m  57.5661\n",
      "      2        \u001b[36m0.2552\u001b[0m       \u001b[32m0.9750\u001b[0m        \u001b[35m0.0823\u001b[0m  61.9020\n",
      "      3        \u001b[36m0.1948\u001b[0m       \u001b[32m0.9794\u001b[0m        \u001b[35m0.0628\u001b[0m  62.9813\n",
      "      4        \u001b[36m0.1688\u001b[0m       0.9789        0.0672  60.8297\n",
      "      5        \u001b[36m0.1544\u001b[0m       \u001b[32m0.9830\u001b[0m        \u001b[35m0.0550\u001b[0m  60.7544\n",
      "      6        \u001b[36m0.1424\u001b[0m       0.9823        0.0572  62.7971\n",
      "      7        \u001b[36m0.1309\u001b[0m       0.9825        0.0604  60.3971\n",
      "      8        \u001b[36m0.1302\u001b[0m       \u001b[32m0.9842\u001b[0m        \u001b[35m0.0538\u001b[0m  59.6087\n",
      "      9        \u001b[36m0.1290\u001b[0m       \u001b[32m0.9844\u001b[0m        \u001b[35m0.0530\u001b[0m  59.0908\n",
      "     10        \u001b[36m0.1227\u001b[0m       \u001b[32m0.9852\u001b[0m        \u001b[35m0.0512\u001b[0m  60.5755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=Cnn(\n",
       "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "    (fc1): Linear(in_features=1600, out_features=100, bias=True)\n",
       "    (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       "    (fc1_drop): Dropout(p=0.5, inplace=False)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(XCnn_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cnn = cnn.predict(XCnn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9830285714285715"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of >98% should suffice for this example!\n",
    "\n",
    "Let's see how we fare on the examples that went wrong before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6805555555555556"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test[error_mask], y_pred_cnn[error_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 70% of the previously misclassified images are now correctly identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_example(X_test[error_mask], y_pred_cnn[error_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
